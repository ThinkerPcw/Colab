{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reid_colab.ipynb（副本）",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThinkerPcw/Colab/blob/master/reid_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "pVFRT_xf5wWi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 创建删除文件夹"
      ]
    },
    {
      "metadata": {
        "id": "eOfvO6VfkGOe",
        "colab_type": "code",
        "outputId": "023a3b0a-04b0-45f1-c923-4dcdf9d1c9ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir storage\n",
        "!rm -r sample_data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'sample_data': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FeHdYI7L5kbz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 挂载google drive,下载数据集,与自己的包"
      ]
    },
    {
      "metadata": {
        "id": "cYdNayVP5YYM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf sample_data\n",
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "drive.mount('/pcw')\n",
        "market_path=\"/pcw/My Drive/Colab/datasets/Market-1501-v15.09.15.zip\"\n",
        "file_zip = zipfile.ZipFile(market_path, 'r')\n",
        "for file in file_zip.namelist():\n",
        "      print(file)\n",
        "      file_zip.extract(file, r'.')\n",
        "\n",
        "reid_path=\"/pcw/My Drive/Colab/datasets/reid.zip\"\n",
        "file_zip = zipfile.ZipFile(reid_path, 'r')\n",
        "for file in file_zip.namelist():\n",
        "      print(file)\n",
        "      file_zip.extract(file, r'.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TR28aJV36Xla",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 从自己的库导入需要的包"
      ]
    },
    {
      "metadata": {
        "id": "oAxwy5P8r0_q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from reid.data import datasets\n",
        "from reid.data import transforms\n",
        "from reid.model.spherenet import *\n",
        "from reid.utils import feature_operate as FO\n",
        "from reid.utils.model_save_restore import *\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "from reid.evaluation import market_evaluate\n",
        "from reid.data.samplers import BalancedSampler\n",
        "import torch\n",
        "from torch.nn import CrossEntropyLoss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mAf7EWzH6hVL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 定义数据加载"
      ]
    },
    {
      "metadata": {
        "id": "jwZ-o-Lfr5Zq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EPOCH = 140\n",
        "LR = 0.02\n",
        "\n",
        "train_image_path = \"./Market-1501-v15.09.15/bounding_box_train\"\n",
        "query_path = \"./Market-1501-v15.09.15/query\"\n",
        "gallery_path = \"./Market-1501-v15.09.15/bounding_box_test\"\n",
        "\n",
        "save_path = './storage'\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomSizedRectCrop(256, 128),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "train_dataset = datasets.MarketDataset(image_path=train_image_path, transform=train_transform, use_onehot=False)\n",
        "sampler = BalancedSampler(train_dataset, 20, 6)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_sampler=sampler, num_workers=4)\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "query_dataset = datasets.MarketDataset(image_path=query_path, transform=test_transform, use_onehot=False)\n",
        "gallery_dataset = datasets.MarketDataset(image_path=gallery_path, transform=test_transform, use_onehot=False)\n",
        "query_loader = DataLoader(query_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
        "gallery_loader = DataLoader(gallery_dataset, batch_size=16, shuffle=False, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i7i-Br5l76ab",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 定义模型，并将训练好的模型保存到google drive"
      ]
    },
    {
      "metadata": {
        "id": "mSR_3tbSrXh6",
        "colab_type": "code",
        "outputId": "9d884a18-e2e5-4b9b-8b2b-c2758cc998d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4785
        }
      },
      "cell_type": "code",
      "source": [
        "net = nn.DataParallel(spherenet50()).cuda()\n",
        "print(net)\n",
        "\n",
        "\n",
        "loss = CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, weight_decay=5e-4)\n",
        "\n",
        "\n",
        "def lr_scheduler(epoch, optimizer):\n",
        "    warmup_epoch = 20\n",
        "    warmup_lr = 5e-5\n",
        "    start_lr = 1e-3\n",
        "    lr_steps = [80, 100]\n",
        "    lr_factor = 0.1\n",
        "    if epoch < warmup_epoch:  # warmup\n",
        "        warmup_scale = (start_lr / warmup_lr) ** (1.0 / warmup_epoch)\n",
        "        lr = warmup_lr * (warmup_scale ** epoch)\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "        optimizer.defaults['lr'] = lr\n",
        "    else:\n",
        "        for i, el in enumerate(lr_steps):\n",
        "            if epoch == el:\n",
        "                lr = start_lr * (lr_factor ** (i + 1))\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = lr\n",
        "                optimizer.defaults['lr'] = lr\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "step = 0\n",
        "best_map = -1\n",
        "best_map_epoch = 0\n",
        "best_rank1 = -1\n",
        "best_rank1_epoch = 0\n",
        "print(\"开始训练>>>\")\n",
        "for epoch in range(EPOCH):\n",
        "    optimizer = lr_scheduler(epoch, optimizer)\n",
        "    for images, ids, cams in train_loader:\n",
        "        predict = net(images.cuda())\n",
        "        loss_value = loss(predict, ids.cuda())\n",
        "        optimizer.zero_grad()\n",
        "        loss_value.backward()\n",
        "        optimizer.step()\n",
        "        if step % 10 == 0:\n",
        "            print(step, loss_value.item())\n",
        "        step += 1\n",
        "    if epoch + 1 >= 10 and (epoch + 1) % 10 == 0:\n",
        "        print(\"第{}轮效果评估开始>>>\".format(epoch + 1))\n",
        "        query_feature = FO.extract_cnn_feature(net, loader=query_loader, vis=False)\n",
        "        gallery_feature = FO.extract_cnn_feature(net, loader=gallery_loader, vis=False)\n",
        "        query_id, query_camera = query_loader.dataset.original_id, query_loader.dataset.cameras\n",
        "        gallery_id, gallery_camera = gallery_loader.dataset.original_id, gallery_loader.dataset.cameras\n",
        "        map, cmc = market_evaluate.evaluate(query_feature, np.array(query_id), np.array(query_camera), gallery_feature,\n",
        "                                            np.array(gallery_id), np.array(gallery_camera), vis=False)\n",
        "        print(\"第{}轮训练结果: map:{},rank-1:{}\".format(epoch + 1, map, cmc[0]))\n",
        "        if map > best_map or cmc[0] > best_rank1:\n",
        "            save_network(save_path, net, epoch)\n",
        "            with open('./storage/net_{}.pth'.format(epoch),'r') as f,open('../pcw/My Drive/Colab/experiment/storage/net_{}.pth'.format(epoch),\"w\") as fw:\n",
        "                 fw.write(f.read())\n",
        "        if map > best_map:\n",
        "            best_map = map\n",
        "            best_map_epoch = epoch\n",
        "        if cmc[0] > best_rank1:\n",
        "            best_rank1 = cmc[0]\n",
        "            best_cmc_epoch = epoch\n",
        "    print(\"已经训练了{}个epoch\".format(epoch + 1))\n",
        "print(\"最佳map:{},最佳rank-1{},最佳map训练轮数:{},最佳cmc训练轮数:{}\".format(best_map, best_rank1, best_map_epoch, best_rank1_epoch))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DataParallel(\n",
            "  (module): SphereNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace)\n",
            "      )\n",
            "    )\n",
            "    (bn2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (dp): Dropout(p=0.5)\n",
            "    (fc): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n",
            "开始训练>>>\n",
            "0 6.688785076141357\n",
            "10 6.710383892059326\n",
            "20 6.707155227661133\n",
            "30 6.7096943855285645\n",
            "已经训练了1个epoch\n",
            "40 6.6851959228515625\n",
            "50 6.5682597160339355\n",
            "60 6.536504745483398\n",
            "70 6.4812211990356445\n",
            "已经训练了2个epoch\n",
            "80 6.282196044921875\n",
            "90 6.328754901885986\n",
            "100 6.409129619598389\n",
            "110 6.4309611320495605\n",
            "已经训练了3个epoch\n",
            "120 6.176629543304443\n",
            "130 6.369878768920898\n",
            "140 6.064362049102783\n",
            "已经训练了4个epoch\n",
            "150 5.954784870147705\n",
            "160 5.917525768280029\n",
            "170 5.971678256988525\n",
            "180 5.897976398468018\n",
            "已经训练了5个epoch\n",
            "190 5.605058670043945\n",
            "200 5.629030227661133\n",
            "210 5.585892677307129\n",
            "220 5.72274923324585\n",
            "已经训练了6个epoch\n",
            "230 5.263656139373779\n",
            "240 5.344727516174316\n",
            "250 5.470550060272217\n",
            "已经训练了7个epoch\n",
            "260 5.05599308013916\n",
            "270 5.035676002502441\n",
            "280 5.145112037658691\n",
            "290 5.307270526885986\n",
            "已经训练了8个epoch\n",
            "300 4.684998989105225\n",
            "310 4.872565269470215\n",
            "320 4.990391254425049\n",
            "330 5.184939861297607\n",
            "已经训练了9个epoch\n",
            "340 4.462175369262695\n",
            "350 4.780466556549072\n",
            "360 4.698435306549072\n",
            "第10轮效果评估开始>>>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sB9EHe9udets",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "10:31"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UOlPIMUr-80_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('./storage/net_129.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3j07DVYxwRy6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# with open('./sample_data/README.md','r') as f,open(\"../pcw/My Drive/Colab/experiment/storage/hah.md\",\"w\") as fw:\n",
        "#    fw.write(f.read())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}